# DataSet
## Задание

В данной лабораторной работе требуется сформировать набор данных. Для этого необходимо распарсить какой-нибудь ресурс.

- Выберите веб-сайт, который вы будете парсить. Сайт должен содержать список каких-нибудь однотипных объектов в неструктурированном виде. Если вы будете парсить готовую таблицу или json, то за это будут снижены баллы. 

- Наборы данных должны быть уникальны. Если вы парсите один и тот же сайт с другим студентом, то у вас должны различаться подкатегории объектов на этом сайте. Для это существует специальная таблица, в которую необходимо предварительно записаться.

- Набор данных должен содержать как минимум 2 категориальных и 2 числовых признака. Всего должно быть не менее 6 признаков.

- Набор данных должен содержать не менее 500 строк (объектов).

- Набор данных может содержать другие типы данных: текст, картинки, аудио, видео, ряды и т.д. Они могут пригодиться в соответствующих лабораторных работах. Если вам не хватает текстовых и категориальных признаков, то необходимо их извлечь в рамках данной лабораторной работы.

- На стадии парсинга запрещено отбрасывать объекты или признаки с пропусками, отбрасывать аномальные объекты, заменять аномальные или пропущенные значения, сливать несколько разных значений категории в одно, пытаться нормализовать значения.

- На стадии парсинга необходимо унифицировать единицы измерения и «очищать» числовые значения от форматирования, например: превращать «1 234 567 м.» или «1,234.567 км.» в «1234567». Единицы измерения нужно сохранить в названии признака.

- На стадии парсинга необходимо унифицировать одинаковые значения одной категории, например: превращать «Cat», «CAT» или «кот» в «cat».

- Набор данных необходимо сохранить в сыром виде в tsv формате. Затем преобразовать в arff формат с определением типов признаков и описанием.

- Набор данных необходимо предобработать: выбрать целевой категориальный признак, заполнить пропуски, преобразовать не целевые категории в числа, нормализовать набор данных. Это необходимо делать после сохранения в tsv и arff форматы. Данные после преобразования можно тоже сохранить, например в csv формат.

Вы можете использовать любые вспомогательные библиотеки. Например, requests для краулинга и lxml для парсинга в python.
